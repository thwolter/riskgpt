{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Challenge Questions, Challenge Risk, and Enrich Context Workflow\n",
    "\n",
    "This notebook demonstrates how to use the challenge_questions, challenge_risk chains, and the enrich_context workflow in RiskGPT.\n"
   ],
   "id": "87b9bb568f9f4b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, let's install RiskGPT and set up the OpenAI API key.\n"
   ],
   "id": "1835b60c61d1624f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Install RiskGPT directly from GitHub (if needed)\n",
    "# !pip install git+https://github.com/thwolter/riskgpt.git\n",
    "\n",
    "# Import required modules\n",
    "import os\n",
    "from getpass import getpass\n",
    "import asyncio\n",
    "\n",
    "# Prompt for OpenAI API key (this way it won't be visible in the notebook)\n",
    "openai_api_key = getpass(\"Enter your OpenAI API key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "# Optional: Set other configuration variables if needed\n",
    "os.environ[\"OPENAI_MODEL_NAME\"] = \"openai:gpt-4.1-nano\"  # Default model\n",
    "os.environ[\"MEMORY_TYPE\"] = \"buffer\"  # Default memory type\n",
    "\n",
    "# Configure logging\n",
    "from riskgpt.logger import configure_logging\n",
    "configure_logging()\n"
   ],
   "id": "c14830533fc51fbe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Create a Business Context\n",
    "\n",
    "Let's create a business context that we'll use throughout this notebook.\n"
   ],
   "id": "310c08bab77a10c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T16:13:58.256566Z",
     "start_time": "2025-06-26T16:13:58.120543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from riskgpt.models.common import BusinessContext\n",
    "from riskgpt.models.chains.risk import Risk\n",
    "from riskgpt.models.enums import AudienceEnum\n",
    "\n",
    "# Create a business context\n",
    "context = BusinessContext(\n",
    "    project_id=\"CLOUD-2023\",\n",
    "    project_description=\"Migrate on-premises infrastructure to cloud services\",\n",
    "    domain_knowledge=\"The company is a financial services provider with strict regulatory requirements\",\n",
    "    business_area=\"IT Infrastructure\",\n",
    "    industry_sector=\"Financial Services\"\n",
    ")\n",
    "\n",
    "# Create a sample risk\n",
    "sample_risk = Risk(\n",
    "    title=\"Data Security Breach\",\n",
    "    description=\"Risk of unauthorized access to sensitive data during migration\",\n",
    "    category=\"Security\",\n",
    ")\n"
   ],
   "id": "ffdf3fc08d6e92f4",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Challenge Questions Chain\n",
    "\n",
    "The challenge_questions_chain generates challenging questions from a business context that can be used for internet searches.\n"
   ],
   "id": "2ed4ecf5a448076d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T16:19:11.280909Z",
     "start_time": "2025-06-26T16:19:08.949902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from riskgpt.models.chains.questions import ChallengeQuestionsRequest\n",
    "from riskgpt.chains.challenge_questions import challenge_questions_chain\n",
    "\n",
    "# Create a request\n",
    "questions_request = ChallengeQuestionsRequest(\n",
    "    business_context=context,\n",
    "    audience=AudienceEnum.risk_internal,\n",
    "    focus_areas=[\"data security\", \"compliance\", \"service continuity\"],\n",
    "    num_questions=5\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "async def run_challenge_questions():\n",
    "    response = await challenge_questions_chain(questions_request)\n",
    "    print(f\"Generated {len(response.questions)} challenging questions:\")\n",
    "    for i, question in enumerate(response.questions, 1):\n",
    "        print(f\"{i}. {question}\")\n",
    "    return response\n",
    "\n",
    "# Execute the async function\n",
    "challenge_questions_response = await run_challenge_questions()\n"
   ],
   "id": "aaab67fad220c6d9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 18:19:11,278 - src - INFO - Consumed 821 tokens (0.0001 USD) for 'challenge_questions' using openai:gpt-4.1-nano\n",
      "2025-06-26 18:19:11,278 - src - INFO - Consumed 821 tokens (0.0001 USD) for 'challenge_questions' using openai:gpt-4.1-nano\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5 challenging questions:\n",
      "1. What are the specific data security risks associated with migrating sensitive financial data to cloud services under strict regulatory requirements?\n",
      "2. How can the company ensure compliance with financial industry regulations during the cloud migration process to mitigate legal and operational risks?\n",
      "3. What potential service continuity challenges might arise during the transition from on-premises infrastructure to cloud, and how can they be proactively addressed?\n",
      "4. In what ways can cloud service providers' security measures impact the company's ability to meet financial compliance standards and protect client data?\n",
      "5. What are the key risk factors for data breaches or loss during the migration, and what best practices can mitigate these risks in a regulated financial environment?\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Challenge Risk Chain\n",
    "\n",
    "The challenge_risk_chain generates challenging questions for a specific risk to help stakeholders better understand and address the risk.\n"
   ],
   "id": "ebec3f137c5eb76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T16:19:48.495945Z",
     "start_time": "2025-06-26T16:19:45.543034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from riskgpt.models.chains.questions import ChallengeRiskRequest\n",
    "from riskgpt.chains.challenge_risk import challenge_risk_chain\n",
    "\n",
    "# Create a request\n",
    "risk_request = ChallengeRiskRequest(\n",
    "    risk=sample_risk,\n",
    "    business_context=context,\n",
    "    audience=AudienceEnum.risk_internal,\n",
    "    focus_areas=[\"data encryption\", \"access controls\", \"regulatory compliance\"],\n",
    "    num_questions=5\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "async def run_challenge_risk():\n",
    "    response = await challenge_risk_chain(risk_request)\n",
    "    print(f\"Generated {len(response.questions)} challenging questions for risk '{sample_risk.title}':\")\n",
    "    for i, question in enumerate(response.questions, 1):\n",
    "        print(f\"{i}. {question}\")\n",
    "    return response\n",
    "\n",
    "# Execute the async function\n",
    "challenge_risk_response = await run_challenge_risk()\n"
   ],
   "id": "df625bf33163c408",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomas/PycharmProjects/projectrm/riskgpt/.venv/lib/python3.12/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n",
      "2025-06-26 18:19:48,489 - src - INFO - Consumed 982 tokens (0.0002 USD) for 'challenge_risk' using openai:gpt-4.1-nano\n",
      "2025-06-26 18:19:48,489 - src - INFO - Consumed 982 tokens (0.0002 USD) for 'challenge_risk' using openai:gpt-4.1-nano\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5 challenging questions for risk 'Data Security Breach':\n",
      "1. How robust are the existing data encryption protocols during migration, and have they been tested against advanced threat scenarios specific to financial regulatory environments?\n",
      "2. What specific access control mechanisms are in place for the migration process, and how are they monitored to prevent privilege escalation or insider threats?\n",
      "3. In what ways might regulatory compliance requirements, such as GDPR or industry-specific standards, influence the design and implementation of data security measures during migration?\n",
      "4. Have potential vulnerabilities introduced by temporary data storage or transit points during migration been thoroughly assessed, and what mitigation strategies are in place to address them?\n",
      "5. Are there any blind spots in the risk assessment that assume encryption alone suffices, neglecting the importance of comprehensive logging, audit trails, and real-time monitoring for early breach detection?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h6/r0s270_97wb3r2f1260jl66r0000gn/T/ipykernel_93961/1752862178.py:22: RuntimeWarning: coroutine 'run_challenge_risk' was never awaited\n",
      "  challenge_risk_response = await run_challenge_risk()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Enrich Context Workflow\n",
    "\n",
    "The enrich_context workflow enriches a business context with external information from various sources (news, professional, regulatory).\n"
   ],
   "id": "e6e8aec22d57579d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T16:20:39.608108Z",
     "start_time": "2025-06-26T16:20:04.065050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from riskgpt.models.workflows.context import EnrichContextRequest\n",
    "from riskgpt.workflows.enrich_context import enrich_context\n",
    "\n",
    "# Create a request\n",
    "enrich_request = EnrichContextRequest(\n",
    "    business_context=context,\n",
    "    focus_keywords=[\"cloud migration\", \"financial services\", \"data security\"],\n",
    "    time_horizon_months=12\n",
    ")\n",
    "\n",
    "# Run the workflow\n",
    "async def run_enrich_context():\n",
    "    response = await enrich_context(enrich_request)\n",
    "    print(\"Sector Summary:\")\n",
    "    print(response.sector_summary)\n",
    "    print(\"\\nWorkshop Recommendations:\")\n",
    "    for i, rec in enumerate(response.workshop_recommendations, 1):\n",
    "        print(f\"{i}. {rec}\")\n",
    "    if response.full_report:\n",
    "        print(\"\\nFull Report:\")\n",
    "        print(response.full_report[:500] + \"...\" if len(response.full_report) > 500 else response.full_report)\n",
    "    return response\n",
    "\n",
    "# Execute the async function\n",
    "enrich_context_response = await run_enrich_context()\n"
   ],
   "id": "e4e9e1a2df9a6ee0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomas/PycharmProjects/projectrm/riskgpt/.venv/lib/python3.12/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n",
      "/Users/thomas/PycharmProjects/projectrm/riskgpt/.venv/lib/python3.12/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n",
      "/Users/thomas/PycharmProjects/projectrm/riskgpt/.venv/lib/python3.12/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n",
      "/Users/thomas/PycharmProjects/projectrm/riskgpt/.venv/lib/python3.12/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n",
      "2025-06-26 18:20:18,080 - src - INFO - Consumed 3670 tokens (0.0006 USD) for 'extract_regulatory_key_points' using openai:gpt-4.1-nano\n",
      "2025-06-26 18:20:18,080 - src - INFO - Consumed 3670 tokens (0.0006 USD) for 'extract_regulatory_key_points' using openai:gpt-4.1-nano\n",
      "/Users/thomas/PycharmProjects/projectrm/riskgpt/.venv/lib/python3.12/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n",
      "2025-06-26 18:20:18,477 - src - INFO - Consumed 4048 tokens (0.0006 USD) for 'extract_news_key_points' using openai:gpt-4.1-nano\n",
      "2025-06-26 18:20:18,477 - src - INFO - Consumed 4048 tokens (0.0006 USD) for 'extract_news_key_points' using openai:gpt-4.1-nano\n",
      "/Users/thomas/PycharmProjects/projectrm/riskgpt/.venv/lib/python3.12/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n",
      "2025-06-26 18:20:21,355 - src - INFO - Consumed 3802 tokens (0.0006 USD) for 'extract_linkedin_key_points' using openai:gpt-4.1-nano\n",
      "2025-06-26 18:20:21,355 - src - INFO - Consumed 3802 tokens (0.0006 USD) for 'extract_linkedin_key_points' using openai:gpt-4.1-nano\n",
      "/Users/thomas/PycharmProjects/projectrm/riskgpt/.venv/lib/python3.12/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n",
      "2025-06-26 18:20:22,747 - src - INFO - Consumed 2551 tokens (0.0004 USD) for 'extract_regulatory_key_points' using openai:gpt-4.1-nano\n",
      "2025-06-26 18:20:22,747 - src - INFO - Consumed 2551 tokens (0.0004 USD) for 'extract_regulatory_key_points' using openai:gpt-4.1-nano\n",
      "/Users/thomas/PycharmProjects/projectrm/riskgpt/.venv/lib/python3.12/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n",
      "2025-06-26 18:20:24,620 - src - INFO - Consumed 2968 tokens (0.0005 USD) for 'extract_news_key_points' using openai:gpt-4.1-nano\n",
      "2025-06-26 18:20:24,620 - src - INFO - Consumed 2968 tokens (0.0005 USD) for 'extract_news_key_points' using openai:gpt-4.1-nano\n",
      "/Users/thomas/PycharmProjects/projectrm/riskgpt/.venv/lib/python3.12/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n",
      "2025-06-26 18:20:26,418 - src - INFO - Consumed 2521 tokens (0.0004 USD) for 'extract_linkedin_key_points' using openai:gpt-4.1-nano\n",
      "2025-06-26 18:20:26,418 - src - INFO - Consumed 2521 tokens (0.0004 USD) for 'extract_linkedin_key_points' using openai:gpt-4.1-nano\n",
      "/Users/thomas/PycharmProjects/projectrm/riskgpt/.venv/lib/python3.12/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n",
      "2025-06-26 18:20:26,981 - src - INFO - Consumed 2013 tokens (0.0003 USD) for 'extract_regulatory_key_points' using openai:gpt-4.1-nano\n",
      "2025-06-26 18:20:26,981 - src - INFO - Consumed 2013 tokens (0.0003 USD) for 'extract_regulatory_key_points' using openai:gpt-4.1-nano\n",
      "2025-06-26 18:20:29,230 - src - INFO - Consumed 3340 tokens (0.0005 USD) for 'extract_news_key_points' using openai:gpt-4.1-nano\n",
      "2025-06-26 18:20:29,230 - src - INFO - Consumed 3340 tokens (0.0005 USD) for 'extract_news_key_points' using openai:gpt-4.1-nano\n",
      "2025-06-26 18:20:30,979 - src - INFO - Consumed 1978 tokens (0.0003 USD) for 'extract_linkedin_key_points' using openai:gpt-4.1-nano\n",
      "2025-06-26 18:20:30,979 - src - INFO - Consumed 1978 tokens (0.0003 USD) for 'extract_linkedin_key_points' using openai:gpt-4.1-nano\n",
      "2025-06-26 18:20:39,592 - src - INFO - Consumed 12657 tokens (0.0015 USD) for 'keypoint_text' using openai:gpt-4.1-nano\n",
      "2025-06-26 18:20:39,592 - src - INFO - Consumed 12657 tokens (0.0015 USD) for 'keypoint_text' using openai:gpt-4.1-nano\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sector Summary:\n",
      "Collected 72 external sources for CLOUD-2023.\n",
      "\n",
      "Workshop Recommendations:\n",
      "1. Review source: How Does Infrastructure Modernization Impact Healthcare Security? - HealthTech Magazine (https://healthtechmagazine.net/article/2025/06/how-does-infrastructure-modernization-impact-healthcare-security)\n",
      "2. Review source: Microsoft Extends Windows 10 Security Updates for One Year with New Enrollment Options - The Hacker News (https://thehackernews.com/2025/06/microsoft-extends-windows-10-security.html)\n",
      "\n",
      "Full Report:\n",
      "Cloud migration involves transferring a financial institution's data, applications, and IT operations from on-premises systems to cloud-based environments, enabling firms to leverage the scalability, flexibility, and efficiency of cloud technology while maintaining secure operations (Pendello, 2023). This process allows organizations to reduce costs, improve data accessibility, and enhance disaster recovery capabilities through incremental data transfer using hybrid solutions, alongside assessin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h6/r0s270_97wb3r2f1260jl66r0000gn/T/ipykernel_93961/3333358211.py:25: RuntimeWarning: coroutine 'run_enrich_context' was never awaited\n",
      "  enrich_context_response = await run_enrich_context()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Combining the Workflows\n",
    "\n",
    "Now let's see how we can combine these workflows to create a more comprehensive risk analysis.\n"
   ],
   "id": "589eac6234c02e8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "async def combined_workflow():\n",
    "    # Step 1: Enrich the context with external information\n",
    "    print(\"Step 1: Enriching context with external information...\")\n",
    "    enrich_response = await enrich_context(enrich_request)\n",
    "    \n",
    "    # Step 2: Generate challenging questions based on the enriched context\n",
    "    print(\"\\nStep 2: Generating challenging questions...\")\n",
    "    questions_response = await challenge_questions_chain(questions_request)\n",
    "    \n",
    "    # Step 3: Generate challenging questions for a specific risk\n",
    "    print(\"\\nStep 3: Generating challenging questions for a specific risk...\")\n",
    "    risk_response = await challenge_risk_chain(risk_request)\n",
    "    \n",
    "    # Return all responses\n",
    "    return {\n",
    "        \"enrich_response\": enrich_response,\n",
    "        \"questions_response\": questions_response,\n",
    "        \"risk_response\": risk_response\n",
    "    }\n",
    "\n",
    "# Execute the combined workflow\n",
    "combined_results = asyncio.run(combined_workflow())\n",
    "\n",
    "# Display a summary of the results\n",
    "print(\"\\nSummary of Combined Workflow:\")\n",
    "print(f\"- Enriched context with {len(combined_results['enrich_response'].workshop_recommendations)} recommendations\")\n",
    "print(f\"- Generated {len(combined_results['questions_response'].questions)} challenging questions from business context\")\n",
    "print(f\"- Generated {len(combined_results['risk_response'].questions)} challenging questions for risk '{sample_risk.title}'\")\n"
   ],
   "id": "d950b109af51efc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use the challenge_questions, challenge_risk chains, and the enrich_context workflow in RiskGPT. These tools can help risk managers and stakeholders better understand and address risks in their projects.\n",
    "\n",
    "Key takeaways:\n",
    "- The challenge_questions_chain generates questions from a business context for internet searches\n",
    "- The challenge_risk_chain generates questions for a specific risk to help stakeholders address it\n",
    "- The enrich_context workflow enriches a business context with external information\n",
    "- These tools can be combined to create a comprehensive risk analysis workflow"
   ],
   "id": "7bbcfc1a22ade1b5"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
