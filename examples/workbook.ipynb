{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Challenge Questions, Challenge Risk, and Enrich Context Workflow\n",
    "\n",
    "This notebook demonstrates how to use the challenge_questions, challenge_risk chains, and the enrich_context workflow in RiskGPT.\n"
   ],
   "id": "87b9bb568f9f4b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, let's install RiskGPT and set up the OpenAI API key.\n"
   ],
   "id": "1835b60c61d1624f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Install RiskGPT directly from GitHub (if needed)\n",
    "# !pip install git+https://github.com/thwolter/riskgpt.git\n",
    "\n",
    "# Import required modules\n",
    "import os\n",
    "from getpass import getpass\n",
    "import asyncio\n",
    "\n",
    "# Prompt for OpenAI API key (this way it won't be visible in the notebook)\n",
    "openai_api_key = getpass(\"Enter your OpenAI API key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "# Optional: Set other configuration variables if needed\n",
    "os.environ[\"OPENAI_MODEL_NAME\"] = \"openai:gpt-4.1-nano\"  # Default model\n",
    "os.environ[\"MEMORY_TYPE\"] = \"buffer\"  # Default memory type\n",
    "\n",
    "# Configure logging\n",
    "from riskgpt.logger import configure_logging\n",
    "configure_logging()\n"
   ],
   "id": "c14830533fc51fbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Create a Business Context\n",
    "\n",
    "Let's create a business context that we'll use throughout this notebook.\n"
   ],
   "id": "310c08bab77a10c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T17:23:57.133779Z",
     "start_time": "2025-06-26T17:23:57.123219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from riskgpt.models.common import BusinessContext\n",
    "from riskgpt.models.chains.risk import Risk\n",
    "from riskgpt.models.enums import AudienceEnum\n",
    "\n",
    "# Create a business context\n",
    "context = BusinessContext(\n",
    "    project_id=\"CLOUD-2023\",\n",
    "    project_description=\"Migrate on-premises infrastructure to cloud services\",\n",
    "    domain_knowledge=\"The company is a financial services provider with strict regulatory requirements\",\n",
    "    business_area=\"IT Infrastructure\",\n",
    "    industry_sector=\"Financial Services\"\n",
    ")\n",
    "\n",
    "# Create a sample risk\n",
    "sample_risk = Risk(\n",
    "    title=\"Data Security Breach\",\n",
    "    description=\"Risk of unauthorized access to sensitive data during migration\",\n",
    "    category=\"Security\",\n",
    ")\n"
   ],
   "id": "ffdf3fc08d6e92f4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Challenge Questions Chain\n",
    "\n",
    "The challenge_questions_chain generates challenging questions from a business context that can be used for internet searches.\n"
   ],
   "id": "2ed4ecf5a448076d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T17:24:05.120142Z",
     "start_time": "2025-06-26T17:24:02.821347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from riskgpt.models.chains.questions import ChallengeQuestionsRequest\n",
    "from riskgpt.chains.challenge_questions import challenge_questions_chain\n",
    "\n",
    "# Create a request\n",
    "questions_request = ChallengeQuestionsRequest(\n",
    "    business_context=context,\n",
    "    audience=AudienceEnum.risk_internal,\n",
    "    focus_areas=[\"data security\", \"compliance\", \"service continuity\"],\n",
    "    num_questions=5\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "async def run_challenge_questions():\n",
    "    response = await challenge_questions_chain(questions_request)\n",
    "    print(f\"Generated {len(response.questions)} challenging questions:\")\n",
    "    for i, question in enumerate(response.questions, 1):\n",
    "        print(f\"{i}. {question}\")\n",
    "    return response\n",
    "\n",
    "# Execute the async function\n",
    "challenge_questions_response = await run_challenge_questions()\n"
   ],
   "id": "aaab67fad220c6d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5 challenging questions:\n",
      "1. What are the primary data security vulnerabilities associated with migrating sensitive financial data to cloud infrastructure in a highly regulated environment?\n",
      "2. How can the company ensure compliance with strict regulatory requirements during and after the cloud migration process to prevent legal and financial penalties?\n",
      "3. What are the potential risks to service continuity during the transition from on-premises to cloud infrastructure, and how can they be mitigated?\n",
      "4. What challenges might arise in maintaining data integrity and confidentiality when integrating legacy financial systems with cloud services?\n",
      "5. How can the company proactively identify and address emerging cybersecurity threats specific to cloud environments within the financial sector?\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Challenge Risk Chain\n",
    "\n",
    "The challenge_risk_chain generates challenging questions for a specific risk to help stakeholders better understand and address the risk.\n"
   ],
   "id": "ebec3f137c5eb76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T17:24:10.727873Z",
     "start_time": "2025-06-26T17:24:08.614394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from riskgpt.models.chains.questions import ChallengeRiskRequest\n",
    "from riskgpt.chains.challenge_risk import challenge_risk_chain\n",
    "\n",
    "# Create a request\n",
    "risk_request = ChallengeRiskRequest(\n",
    "    risk=sample_risk,\n",
    "    business_context=context,\n",
    "    audience=AudienceEnum.risk_internal,\n",
    "    focus_areas=[\"data encryption\", \"access controls\", \"regulatory compliance\"],\n",
    "    num_questions=3\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "async def run_challenge_risk():\n",
    "    response = await challenge_risk_chain(risk_request)\n",
    "    print(f\"Generated {len(response.questions)} challenging questions for risk '{sample_risk.title}':\")\n",
    "    for i, question in enumerate(response.questions, 1):\n",
    "        print(f\"{i}. {question}\")\n",
    "    return response\n",
    "\n",
    "# Execute the async function\n",
    "challenge_risk_response = await run_challenge_risk()\n"
   ],
   "id": "df625bf33163c408",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3 challenging questions for risk 'Data Security Breach':\n",
      "1. How robust are the encryption protocols applied during data transfer and storage, and have they been tested against evolving threat vectors specific to financial data?\n",
      "2. In what ways are access controls, including identity management and multi-factor authentication, validated to prevent privilege escalation or insider threats during and after migration?\n",
      "3. Are the compliance and regulatory requirements for data security explicitly integrated into the migration plan, and how are potential gaps in adherence identified and addressed prior to execution?\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Enrich Context Workflow\n",
    "\n",
    "The enrich_context workflow enriches a business context with external information from various sources (news, professional, regulatory).\n"
   ],
   "id": "e6e8aec22d57579d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T17:27:53.205728Z",
     "start_time": "2025-06-26T17:27:46.103044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from riskgpt.models.workflows.context import EnrichContextRequest\n",
    "from riskgpt.workflows.enrich_context import enrich_context\n",
    "\n",
    "# Create a request\n",
    "enrich_request = EnrichContextRequest(\n",
    "    business_context=context,\n",
    "    focus_keywords=[\"cloud migration\", \"financial services\", \"data security\"],\n",
    "    time_horizon_months=12\n",
    ")\n",
    "\n",
    "# Run the workflow\n",
    "async def run_enrich_context():\n",
    "    response = await enrich_context(enrich_request)\n",
    "    print(\"Sector Summary:\")\n",
    "    print(response.sector_summary)\n",
    "    print(\"\\nWorkshop Recommendations:\")\n",
    "    for i, rec in enumerate(response.workshop_recommendations, 1):\n",
    "        print(f\"{i}. {rec}\")\n",
    "    if response.full_report:\n",
    "        print(\"\\nFull Report:\")\n",
    "        print(response.full_report[:500] + \"...\" if len(response.full_report) > 500 else response.full_report)\n",
    "    return response\n",
    "\n",
    "# Execute the async function\n",
    "enrich_context_response = await run_enrich_context()\n"
   ],
   "id": "e4e9e1a2df9a6ee0",
   "outputs": [
    {
     "ename": "InvalidUpdateError",
     "evalue": "At key 'search_failed': Can receive only one value per step. Use an Annotated key to handle multiple values.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mInvalidUpdateError\u001B[39m                        Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 25\u001B[39m\n\u001B[32m     22\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m response\n\u001B[32m     24\u001B[39m \u001B[38;5;66;03m# Execute the async function\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m25\u001B[39m enrich_context_response = \u001B[38;5;28;01mawait\u001B[39;00m run_enrich_context()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 13\u001B[39m, in \u001B[36mrun_enrich_context\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mrun_enrich_context\u001B[39m():\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m     response = \u001B[38;5;28;01mawait\u001B[39;00m enrich_context(enrich_request)\n\u001B[32m     14\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mSector Summary:\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     15\u001B[39m     \u001B[38;5;28mprint\u001B[39m(response.sector_summary)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/projectrm/riskgpt/src/riskgpt/workflows/enrich_context.py:271\u001B[39m, in \u001B[36menrich_context\u001B[39m\u001B[34m(request)\u001B[39m\n\u001B[32m    268\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Run the external context enrichment workflow asynchronously.\"\"\"\u001B[39;00m\n\u001B[32m    270\u001B[39m app = _build_graph(request)\n\u001B[32m--> \u001B[39m\u001B[32m271\u001B[39m result = \u001B[38;5;28;01mawait\u001B[39;00m app.ainvoke({})\n\u001B[32m    272\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result[\u001B[33m\"\u001B[39m\u001B[33mresponse\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/projectrm/riskgpt/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2788\u001B[39m, in \u001B[36mPregel.ainvoke\u001B[39m\u001B[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001B[39m\n\u001B[32m   2785\u001B[39m chunks: \u001B[38;5;28mlist\u001B[39m[Union[\u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any], Any]] = []\n\u001B[32m   2786\u001B[39m interrupts: \u001B[38;5;28mlist\u001B[39m[Interrupt] = []\n\u001B[32m-> \u001B[39m\u001B[32m2788\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.astream(\n\u001B[32m   2789\u001B[39m     \u001B[38;5;28minput\u001B[39m,\n\u001B[32m   2790\u001B[39m     config,\n\u001B[32m   2791\u001B[39m     stream_mode=stream_mode,\n\u001B[32m   2792\u001B[39m     output_keys=output_keys,\n\u001B[32m   2793\u001B[39m     interrupt_before=interrupt_before,\n\u001B[32m   2794\u001B[39m     interrupt_after=interrupt_after,\n\u001B[32m   2795\u001B[39m     checkpoint_during=checkpoint_during,\n\u001B[32m   2796\u001B[39m     debug=debug,\n\u001B[32m   2797\u001B[39m     **kwargs,\n\u001B[32m   2798\u001B[39m ):\n\u001B[32m   2799\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m stream_mode == \u001B[33m\"\u001B[39m\u001B[33mvalues\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m   2800\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   2801\u001B[39m             \u001B[38;5;28misinstance\u001B[39m(chunk, \u001B[38;5;28mdict\u001B[39m)\n\u001B[32m   2802\u001B[39m             \u001B[38;5;129;01mand\u001B[39;00m (ints := chunk.get(INTERRUPT)) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   2803\u001B[39m         ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/projectrm/riskgpt/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2652\u001B[39m, in \u001B[36mPregel.astream\u001B[39m\u001B[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001B[39m\n\u001B[32m   2646\u001B[39m     get_waiter = \u001B[38;5;28;01mNone\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[assignment]\u001B[39;00m\n\u001B[32m   2647\u001B[39m \u001B[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001B[39;00m\n\u001B[32m   2648\u001B[39m \u001B[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001B[39;00m\n\u001B[32m   2649\u001B[39m \u001B[38;5;66;03m# channel updates from step N are only visible in step N+1\u001B[39;00m\n\u001B[32m   2650\u001B[39m \u001B[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001B[39;00m\n\u001B[32m   2651\u001B[39m \u001B[38;5;66;03m# with channel updates applied only at the transition between steps\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2652\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[43mloop\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtick\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minput_channels\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[32m   2653\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m task \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m loop.amatch_cached_writes():\n\u001B[32m   2654\u001B[39m         loop.output_writes(task.id, task.writes, cached=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/projectrm/riskgpt/.venv/lib/python3.12/site-packages/langgraph/pregel/loop.py:493\u001B[39m, in \u001B[36mPregelLoop.tick\u001B[39m\u001B[34m(self, input_keys)\u001B[39m\n\u001B[32m    483\u001B[39m     print_step_writes(\n\u001B[32m    484\u001B[39m         \u001B[38;5;28mself\u001B[39m.step,\n\u001B[32m    485\u001B[39m         writes,\n\u001B[32m   (...)\u001B[39m\u001B[32m    490\u001B[39m         ),\n\u001B[32m    491\u001B[39m     )\n\u001B[32m    492\u001B[39m \u001B[38;5;66;03m# all tasks have finished\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m493\u001B[39m mv_writes, updated_channels = \u001B[43mapply_writes\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    494\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    495\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mchannels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    496\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    497\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcheckpointer_get_next_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    498\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrigger_to_nodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    499\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    500\u001B[39m \u001B[38;5;66;03m# apply writes to managed values\u001B[39;00m\n\u001B[32m    501\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m key, values \u001B[38;5;129;01min\u001B[39;00m mv_writes.items():\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/projectrm/riskgpt/.venv/lib/python3.12/site-packages/langgraph/pregel/algo.py:305\u001B[39m, in \u001B[36mapply_writes\u001B[39m\u001B[34m(checkpoint, channels, tasks, get_next_version, trigger_to_nodes)\u001B[39m\n\u001B[32m    303\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m chan, vals \u001B[38;5;129;01min\u001B[39;00m pending_writes_by_channel.items():\n\u001B[32m    304\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m chan \u001B[38;5;129;01min\u001B[39;00m channels:\n\u001B[32m--> \u001B[39m\u001B[32m305\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mchannels\u001B[49m\u001B[43m[\u001B[49m\u001B[43mchan\u001B[49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvals\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mand\u001B[39;00m get_next_version \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    306\u001B[39m             checkpoint[\u001B[33m\"\u001B[39m\u001B[33mchannel_versions\u001B[39m\u001B[33m\"\u001B[39m][chan] = get_next_version(\n\u001B[32m    307\u001B[39m                 max_version,\n\u001B[32m    308\u001B[39m                 channels[chan],\n\u001B[32m    309\u001B[39m             )\n\u001B[32m    310\u001B[39m             \u001B[38;5;66;03m# unavailable channels can't trigger tasks, so don't add them\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/projectrm/riskgpt/.venv/lib/python3.12/site-packages/langgraph/channels/last_value.py:58\u001B[39m, in \u001B[36mLastValue.update\u001B[39m\u001B[34m(self, values)\u001B[39m\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(values) != \u001B[32m1\u001B[39m:\n\u001B[32m     54\u001B[39m     msg = create_error_message(\n\u001B[32m     55\u001B[39m         message=\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mAt key \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.key\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m: Can receive only one value per step. Use an Annotated key to handle multiple values.\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     56\u001B[39m         error_code=ErrorCode.INVALID_CONCURRENT_GRAPH_UPDATE,\n\u001B[32m     57\u001B[39m     )\n\u001B[32m---> \u001B[39m\u001B[32m58\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m InvalidUpdateError(msg)\n\u001B[32m     60\u001B[39m \u001B[38;5;28mself\u001B[39m.value = values[-\u001B[32m1\u001B[39m]\n\u001B[32m     61\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[31mInvalidUpdateError\u001B[39m: At key 'search_failed': Can receive only one value per step. Use an Annotated key to handle multiple values.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "enrich_context_response.full_report",
   "id": "6be43037b6f3702e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Combining the Workflows\n",
    "\n",
    "Now let's see how we can combine these workflows to create a more comprehensive risk analysis.\n"
   ],
   "id": "589eac6234c02e8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "async def combined_workflow():\n",
    "    # Step 1: Enrich the context with external information\n",
    "    print(\"Step 1: Enriching context with external information...\")\n",
    "    enrich_response = await enrich_context(enrich_request)\n",
    "    \n",
    "    # Step 2: Generate challenging questions based on the enriched context\n",
    "    print(\"\\nStep 2: Generating challenging questions...\")\n",
    "    questions_response = await challenge_questions_chain(questions_request)\n",
    "    \n",
    "    # Step 3: Generate challenging questions for a specific risk\n",
    "    print(\"\\nStep 3: Generating challenging questions for a specific risk...\")\n",
    "    risk_response = await challenge_risk_chain(risk_request)\n",
    "    \n",
    "    # Return all responses\n",
    "    return {\n",
    "        \"enrich_response\": enrich_response,\n",
    "        \"questions_response\": questions_response,\n",
    "        \"risk_response\": risk_response\n",
    "    }\n",
    "\n",
    "# Execute the combined workflow\n",
    "combined_results = asyncio.run(combined_workflow())\n",
    "\n",
    "# Display a summary of the results\n",
    "print(\"\\nSummary of Combined Workflow:\")\n",
    "print(f\"- Enriched context with {len(combined_results['enrich_response'].workshop_recommendations)} recommendations\")\n",
    "print(f\"- Generated {len(combined_results['questions_response'].questions)} challenging questions from business context\")\n",
    "print(f\"- Generated {len(combined_results['risk_response'].questions)} challenging questions for risk '{sample_risk.title}'\")\n"
   ],
   "id": "d950b109af51efc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use the challenge_questions, challenge_risk chains, and the enrich_context workflow in RiskGPT. These tools can help risk managers and stakeholders better understand and address risks in their projects.\n",
    "\n",
    "Key takeaways:\n",
    "- The challenge_questions_chain generates questions from a business context for internet searches\n",
    "- The challenge_risk_chain generates questions for a specific risk to help stakeholders address it\n",
    "- The enrich_context workflow enriches a business context with external information\n",
    "- These tools can be combined to create a comprehensive risk analysis workflow"
   ],
   "id": "7bbcfc1a22ade1b5"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
